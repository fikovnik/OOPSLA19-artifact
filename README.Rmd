---
title: "OOPSLA19 Artifact - Scala Implicits are Everywhere"
authors: "Filip Krikava, Jan Vitek and Heather Miller"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

## Artifact Description

This is the artifact for the paper _Scala Implicits are Everywhere_ at OOPSLA 2019.
The aim is to:

1. show extracting implicit declarations and call sites they are involved in from Scala code,
1. demonstrate running the analysis pipeline, and
1. make available the large corpus of Scala projects used for the paper.

The artifact is composed of 2 two parts.
First will use a sample Scala project to show implicit extract and overview the data model behind.
Then we will show how to extend the analysis for a number of projects.

## Requirements

The pipeline depends on a number of tools.
The full requirements are listed in the documentation of the [analysis pipeline itself](https://github.com/PRL-PRG/scala-implicits-analysis/tree/oopsla19#requirementsalysis/).
To make it more convenient we have build a docker image that has all these dependencies installed.
The image is available on [Docker HUB](https://hub.docker.com/r/prlprg/oopsla19-scala).
This image can be either pulled directly from the Hub or <a href="#building-image-locally">build image locally</a>.
To run the image, you will need [docker community edition](https://docs.docker.com/install/) version 18+ and bash.

## Getting Started Guide

The following steps are intended for the _kick-the-tires phase_ to ensure that all the components work.
If you run into some problems, please check the <a href="#troubleshooting">troubleshooting</a> section we have added at the end.
This guide was tried on Linux and OSX.

1. Clone the artifact

   ```{sh eval=FALSE}
   git clone https://github.com/fikovnik/OOPSLA19-artifact
   ```

   Unless stated otherwise, all the subsequent commands should be run _inside the artifact's directory_:

   ```{sh eval=FALSE}
   cd OOPSLA19-artifact
   ```

   We will refer to it as `$DIR`:
   Just to make sure the commands are executed from the right place.

1. Clone the analysis pipeline:

   It is a separate open source project hosted on GitHub.

   ```{sh eval=FALSE}
   git clone --single-branch --branch oopsla19 https://github.com/PRL-PRG/scala-implicits-analysis
   ```

   It is _important_ that you use =oopsla19= branch:

   ```{sh eval=FALSE}
   git --git-dir=scala-implicits-analysis/.git branch
   * oopsla19
   ```

   After cloning, the artifacts directory should look like:

   ```
   ├── corpora
   │   ├── 1-example            -- an example project to demonstrate implciti extraction
   │   ├── 2-single             -- a single real-world Scala project to check the pipeline
   │   ├── 3-sample-set         -- a sample set of random Scala projects
   │   └── 4-github             -- placeholder for the entire analyzed repository (not downloaded yet)
   ├── docker                   -- the source code for building the docker image
   │   ├── Dockerfile
   │   ├── entrypoint.sh
   │   └── Makefile
   ├── scala-implicits-analysis -- the analysis pipeline (clonned in the last step)
   ├── README.Rmd               -- these instructions
   └── run.sh                   -- this guide
   ```

1. Make sure you have a docker installed and running

   ```{sh eval=FALSE}
   docker run --rm hello-world
   ```

1. Pull the docker image (or <a href="#building-image-locally">build one
   locally</a>)

   ```{sh eval=FALSE}
   docker pull prlprg/oopsla19-scala
   ```

1. Check that the image can be run

   The image needs a number of directories and environment variables set which would make it cumbersome to provide each time.
   There is a bash script `run.sh` that encapsulates all the necessary settings.
   Please use this script to run the image.

   ```{sh eval=FALSE}
   ./run.sh id
   uid=1000(scala) gid=1000(scala) groups=1000(scala),27(sudo)
   ```

   The `uid` and `gid` returned should be the same as are on your host system.
   You can double check that by running `id -u` and `id -g`.
   This is important because while the commands will run in the docker image, they will modify the files in this directory.
   If the `uid` or `gid` are different it will be inconvenient for you to view the results and remove them at the end.

1. Setup a run alias (_optional_)

   There are two ways how to run the tools installed in the image:
   - run `./run.sh bash` and then run all the consecutive commands inside this session
   - run each command from your own shell by prepending the command with the `./run.sh` script

   For the second way, it is convenient to setup a shell alias:

   ```{sh eval=FALSE}
   alias run=$(pwd)/run.sh
   ```

1. Build the pipeline

   The pipeline consists of the following tools:
   - sbt-plugins - a SBT plugin adding `metadata` and `semanticdb` commands for metadata extraction and semanticdb generation.
   - libs - the model of implicits, the implicit extractor and a number of tools that export the results into CSV files.
   - scripts/analysis - R notebooks containing data analysis
   - scripts/tools - a modified version of [Dejavu](https://github.com/PRL-PRG/dejavu-artifact) allowing to index Scala files.

   To build these tools, run the following:

   ```{sh eval=FALSE}
   ./run.sh make -C scala-implicits-analysis
   ```

1. Run the pipeline on a single project corpus

   We will try out the pipeline on the a Scala corpus that contains only one, yet real project.
   The corpus is located in `corpora/2-single` directory.

   ```{sh eval=FALSE}
   ./run.sh make -C corpora/2-single
   ```

1. Check the results

   After the make is done, the should be three HTML files in the corpus directory:

   ```{sh eval=FALSE}
   ls -1 corpora/2-single
   implicits-analysis.html
   stage1-analysis.html
   stage3-analysis.html
   ```

   The `stage*-analysis.html` describes the state of the corpus while the `implicits-analysis.html` summarizes the extracted implicits. The details of what to expect in each of these files follow in the part 2 of this artifact.

## Part 1

## Part 2

### Note about concurrency

## Part 3

The corpus of all the GitHub Scala projects is available on server at:

```
http://prl1.ele.fit.cvut.cz:8149/github
```

If you are concerned about privacy you can access it via a VPN service or TOR although we do not keep any access logs.

The reason why do not create an archive of it is its size:

1. The cache similar to what we have used in this artifact has 110GB:
   - 29GB  `cache/coursier`
   - 79GB  `cache/ivy`
   -  2GB `cache/sbt/sbt-boot`

2. The corpus itself has 1.1TB.

## Building image locally
<a name="#building-image-locally"/>

To build image locally you can either use make by running:

```{sh eval=FALSE}
make -C docker
```

or by directly run `docker build`:

```{sh eval=FALSE}
docker build -t prlprg/oopsla19-scala docker
```

## Toubleshooting
<a name="troubleshooting"/>

### Docker on OSX

It is better to use homebrew cask to install docker:

```sh
brew cask install docker
```

in case you see `docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.` error message
cf: https://stackoverflow.com/a/44719239

### Docker on Linux

In some distribution the package does not add the current user to `docker` group.
In this case, either add yourself to `docker` group or run the `./run*` commands with `sudo`.

### Error: `gpg: keyserver receive failed: Cannot assign requested address= when building image` while building the docker image

The keyserver that is used to add debian APT repositories for newer version of R and SBT sometimes does not work.
What has worked all the time was simply repeating the image build process by rerunning the make.


### Error: A compilation error `Caused by: scala.reflect.internal.MissingRequirementError: object scala in compiler mirror not found.`

Rebuild [BuildInfo](scala-implicits-analysis/libs/tools/target/scala-2.12/src_managed/main/sbt-buildinfo/BuildInfo.scala) file by deleting the file and running `./run.sh make -C scala-implicits-analysis/libs`.

### Out of memory exception

Compiling Scala projects can be rather expensive.
TODO:
